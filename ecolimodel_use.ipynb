{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Device Setting"
      ],
      "metadata": {
        "id": "V5_csnzpWNfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "J_LeXKMKVPDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "# Import for read data function\n",
        "from scipy import io\n",
        "from scipy.io import loadmat\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "9-_o9rBzXZI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## connect to dirve"
      ],
      "metadata": {
        "id": "5OIgPlBEU1QM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imPYUQnXVfbQ",
        "outputId": "6aeac8cc-e831-4d8a-e94a-d2fdd0364062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set GPU"
      ],
      "metadata": {
        "id": "3UFLbzRwU_fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "e4ofHod4VaxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# remove"
      ],
      "metadata": {
        "id": "29-rFn1Q7W_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir('/content')\n",
        "# !ls\n",
        "# !rm -rf test\n",
        "# !ls\n",
        "# !mkdir test\n",
        "# !ls"
      ],
      "metadata": {
        "id": "_SsL2sdo7hKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setting"
      ],
      "metadata": {
        "id": "I2nSMVHa-j1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model structure"
      ],
      "metadata": {
        "id": "dDQnIlVs-tN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,numNeurons=16):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # self.conv1 = nn.Conv2d(1,3,3,stride=2,padding=0)\n",
        "        # self.bn2d1 = nn.BatchNorm2d(3)\n",
        "\n",
        "        self.fc1 = nn.Linear(160, numNeurons*8).double()\n",
        "        self.fc2 = nn.Linear(numNeurons*8, numNeurons*8).double()\n",
        "        self.fc3 = nn.Linear(numNeurons*8, numNeurons*4).double()\n",
        "        self.fc4 = nn.Linear(numNeurons*4, numNeurons*2).double()\n",
        "        self.fc5 = nn.Linear(numNeurons*2, 4).double()\n",
        "        self.dropout=nn.Dropout(p=0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.conv1(x)\n",
        "        # x=self.bn2d1(x)\n",
        "        # x=F.relu6(x)\n",
        "\n",
        "        # x=x.view(x.size()[0],-1) # flatten the activation\n",
        "        x=self.fc1(x)\n",
        "        x=F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x=self.fc2(x)\n",
        "        x=F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x=self.fc3(x)\n",
        "        x=F.relu(x)\n",
        "\n",
        "        x=self.fc4(x)\n",
        "        x=F.relu(x)\n",
        "\n",
        "        x=self.fc5(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "iZF4BLcB-wNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "OTKKjikgWIsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load .mat file"
      ],
      "metadata": {
        "id": "CT4WDGoVHhSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/finetune_1129\"\n",
        "\n",
        "os.chdir(path)\n",
        "files = os.listdir(path)\n",
        "files = [ff for ff in files if '.mat' in ff]\n",
        "\n",
        "def extract_number(filename):\n",
        "    return int(''.join(filter(str.isdigit, filename)))\n",
        "\n",
        "files = sorted(files, key=extract_number)\n",
        "\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-W0nncGXsJf",
        "outputId": "0390c8bd-a2ac-458d-9731-3f635d832ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1s-01-Image(1-14).mat', '1s-02-Image(15-30).mat', '1s-03-Image(31-53).mat', '1s-04-Image(54-70).mat', '1s-05-Image(71-92).mat', '1s-06-Image(93-110).mat', '1s-07-Image(111-126).mat', '1s-08-Image(127-142).mat', '1s-09-Image(143-160).mat', '2s-01-Image(161-164).mat', '2s-02-Image(165-172).mat', '2s-03-Image(173-181).mat', '2s-04-Image(182-188).mat', '2s-05-Image(189-191).mat', '2s-06-Image(192-194).mat', '2s-07-Image(195-198).mat', '2s-08-Image(199-200).mat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data = []\n",
        "\n",
        "for i in files:\n",
        "  f = loadmat(i)\n",
        "  data = f['cellList']['meshData']\n",
        "  cells_file = data[0][0][0][0][0]\n",
        "  # print(len(cells_file))\n",
        "  for j in range (len(cells_file)):\n",
        "    Base = cells_file[j][0][0]\n",
        "    Data.append(Base['signal1'])\n",
        "    Data.append(Base['signal2'])\n",
        "\n",
        "print(len(Data))\n",
        "# print(Data[0])\n",
        "# print(Data[1])"
      ],
      "metadata": {
        "id": "djy0wYziSW_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5883327c-1d47-439f-dc73-8f509e06c6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data preprocessing"
      ],
      "metadata": {
        "id": "ojGyIdRu5Hwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "expand length to 160"
      ],
      "metadata": {
        "id": "H7MYed8NVfT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extrapo(s, extra_length):\n",
        "  desired_length = 80\n",
        "  new_vector = np.zeros(desired_length)\n",
        "\n",
        "  cnt = 0\n",
        "  for i in range(len(s)-1):\n",
        "    cnt = i\n",
        "    if i == extra_length:\n",
        "      break\n",
        "    new_vector[2 * i] = s[i]\n",
        "    new_vector[2 * i + 1] = ((s[i] + s[i+1]) / 2)\n",
        "\n",
        "  cnt_s = cnt\n",
        "  cnt = cnt * 2\n",
        "  nokori_len = len(s) - cnt_s\n",
        "  for i in range(nokori_len):\n",
        "    new_vector[cnt] = s[cnt_s]\n",
        "    cnt += 1\n",
        "    cnt_s += 1\n",
        "\n",
        "  for i in range(desired_length-cnt):\n",
        "    new_vector[cnt+i] = s[cnt_s-1]\n",
        "\n",
        "  return new_vector"
      ],
      "metadata": {
        "id": "Pagw7f4H56ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpo(s):\n",
        "  desired_length = 80\n",
        "\n",
        "  remove_length = len(s) - desired_length\n",
        "  indices_to_remove = random.sample(range(len(s)), remove_length)\n",
        "\n",
        "  new_vector = [value for index, value in enumerate(s) if index not in indices_to_remove]\n",
        "\n",
        "  # print(len(new_vector))\n",
        "  for i in range(len(new_vector)):\n",
        "    new_vector[i] = new_vector[i]*2 / 2\n",
        "\n",
        "  return new_vector"
      ],
      "metadata": {
        "id": "ItiG4lkB56Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_Data = []\n",
        "additional_Data = []\n",
        "indexes = []\n",
        "\n",
        "for i in range(int(len(Data)/2)):\n",
        "  temp1 = [element for sublist in Data[i*2] for element in sublist]\n",
        "  temp1 = np.array(temp1)\n",
        "  # normalize\n",
        "  if max(temp1) != 0:\n",
        "    temp1 = 255*temp1/max(temp1)\n",
        "  # print(len(temp1))\n",
        "  # temp3 = np.flip(temp1)\n",
        "  if len(temp1) < 3:\n",
        "    # indexes.append(i)\n",
        "    print(i, \"<3\")\n",
        "    continue\n",
        "  if len(temp1) < 80:\n",
        "    temp1 = extrapo(temp1, (80-len(temp1)))\n",
        "    # temp3 = extrapo(temp3, (80-len(temp3)))\n",
        "  if len(temp1) >= 80:\n",
        "    temp1 = interpo(temp1)\n",
        "    # print(temp1[0].dtype)\n",
        "\n",
        "  temp2 = [element for sublist in Data[i*2+1] for element in sublist]\n",
        "  temp2 = np.array(temp2)\n",
        "  # normalize\n",
        "  if max(temp2) != 0:\n",
        "    temp2 = 255*temp2/max(temp2)\n",
        "  # temp4 = np.flip(temp2)\n",
        "  if len(temp2) < 80:\n",
        "    temp2 = extrapo(temp2, (80-len(temp2)))\n",
        "    # temp4 = extrapo(temp4, (80-len(temp4)))\n",
        "  if len(temp2) >= 80:\n",
        "    temp2 = interpo(temp2)\n",
        "  temp5 = np.concatenate((temp1, temp2), axis = 0)\n",
        "  modified_Data.append(temp5)\n",
        "\n",
        "  # temp6 = np.concatenate((temp3, temp4), axis = 0)\n",
        "  # additional_Data.append(temp6)\n",
        "\n",
        "# print(modified_Data[4])\n",
        "print(len(modified_Data))\n",
        "print(indexes)\n",
        "# print(modified_Data[1].dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y800JIbS4_ua",
        "outputId": "8860523e-2372-4127-ea78-adca3db50aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "exclude some bad data\n",
        "- length < 3\n",
        "- label = 6"
      ],
      "metadata": {
        "id": "WK5CTlsnVugz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(modified_Data)):\n",
        "#   if labels[i] == 6:\n",
        "#     indexes.append(i)\n",
        "\n",
        "pruned_modified_Data = []\n",
        "# modified_additional_Data = []\n",
        "for i in range(len(modified_Data)):\n",
        "  if i not in indexes:\n",
        "    pruned_modified_Data.append(modified_Data[i])\n",
        "# for i in range(len(additional_Data)):\n",
        "#   if i not in indexes:\n",
        "#     modified_additional_Data.append(additional_Data[i])\n",
        "# pruned_labels = np.delete(labels, indexes)\n",
        "# temp = np.copy(pruned_labels)\n",
        "# pruned_labels = np.concatenate((pruned_labels, temp), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "print(len(indexes))\n",
        "print(len(pruned_modified_Data))\n",
        "# print(len(pruned_labels))\n",
        "print(indexes)\n",
        "# print(pruned_labels)\n",
        "print(pruned_modified_Data[0])\n",
        "print(pruned_modified_Data[0].dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awfRPjQZdqON",
        "outputId": "bbedf1db-7079-476a-ac2b-c289f4577fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "200\n",
            "[]\n",
            "[  0.           2.01026893   4.02053785   6.22972679   8.43891525\n",
            "   8.39430809   8.34969997   6.54216194   4.73462343   5.44377232\n",
            "   6.15292072   6.47055864   6.78819656  11.38145256  15.97470856\n",
            "  10.73902798   5.5033474   12.82868671  20.15402603  18.53079796\n",
            "  16.90756989  13.76337624  10.61918163  20.78191948  30.94465828\n",
            "  29.85037231  28.75608635  28.0682869   27.38048935  26.08950424\n",
            "  24.79851913  23.45892334  22.11932945  25.94384003  29.76834869\n",
            "  26.17612839  22.58390999  32.56075287  42.53759384  39.71721649\n",
            "  36.89684296  47.36993027  57.84301758  51.83301544  45.82301331\n",
            "  57.70750809  69.59200287  69.90341187  70.21481323  83.55450439\n",
            "  96.89419556  90.85340118  84.81260681  95.01677704 105.22094727\n",
            " 108.11608124 111.01121521 102.79483032  94.57844543 119.84204102\n",
            " 145.1056366  148.41462708 151.72361755 193.69422913 235.6648407\n",
            " 232.61160278 229.55836487 255.         248.45753479 184.05410767\n",
            " 100.05764771  85.74124908  32.21974564  42.29249954  31.03929901\n",
            "  28.41490173   9.16154385  11.49632072   7.48430824   0.89031756\n",
            "   0.           1.73960412   3.47920823   3.85572481   4.23224115\n",
            "   4.74357033   5.25489998   5.97467422   6.69444847   5.95400333\n",
            "   5.21355772  10.04134655  14.8691349   13.62650299  12.38387203\n",
            "  15.24894333  18.11401558  18.47681046  18.83960724  21.74074364\n",
            "  24.64188004  21.33804131  18.03420258  19.46292114  20.89164162\n",
            "  20.24402809  19.59641457  20.82987022  22.06332588  24.00273323\n",
            "  25.94214058  21.94348907  17.94483566  23.40439606  28.86395645\n",
            "  26.12777328  23.39158821  25.07815933  26.76473236  27.99693298\n",
            "  29.2291317   33.03322983  36.83732986  34.58605576  32.33478165\n",
            "  32.81243134  33.29008102  34.7205925   36.15110397  34.53818512\n",
            "  32.92526245  34.74012375  36.55498505  37.91954803  39.28411484\n",
            "  43.14261246  47.00111008  50.70196915  54.40282822  62.69176483\n",
            "  70.98069763  71.17593384  71.37117767  81.02947235  90.68776703\n",
            "  97.37467957 104.06159973 109.83591461 141.07015991 160.12005615\n",
            " 173.17155457 204.63998413 213.99162292 255.00001526 234.29171753\n",
            " 254.51928711 201.4213562  148.76034546  87.04566956  19.35741043]\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build dataset"
      ],
      "metadata": {
        "id": "2St0kjjQWCim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "          return self.data[idx], self.labels[idx]\n",
        "        else:\n",
        "          return self.data[idx]"
      ],
      "metadata": {
        "id": "FfGc3HxJZ-ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a dataset for testing"
      ],
      "metadata": {
        "id": "oLQk2mnC3tXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "\n",
        "test_data = pruned_modified_Data\n",
        "test_data_tensor = [torch.from_numpy(sample) for sample in test_data]\n",
        "test_set = MyDataset(test_data_tensor, None)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(test_data[1].dtype)"
      ],
      "metadata": {
        "id": "1qOutMoZ39_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50345f4-c152-4157-f394-b1eb96ede16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "DAjz8OCCV69o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make prediction"
      ],
      "metadata": {
        "id": "LlbhAnz774v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content\")\n",
        "predict = []\n",
        "model = Model().to(device)\n",
        "model.load_state_dict(torch.load(\"drive/MyDrive/Model_5.pt\"))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        # print(i)\n",
        "        # print(data)\n",
        "        inputs = data\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "        for y in test_pred.cpu().numpy():\n",
        "            predict.append(y)\n",
        "\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "bceK6yvaV6Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3225695f-d23a-4af1-c5e8-ebe7ca63cd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-641fd0191e8b>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"drive/MyDrive/Model_5.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 0, 2, 0, 1, 1, 3, 2, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 3, 3, 1, 3, 3, 2, 0, 3, 2, 1, 3, 1, 1, 0, 1, 3, 2, 1, 2, 1, 3, 0, 0, 1, 1, 2, 0, 1, 3, 3, 1, 1, 3, 1, 1, 3, 2, 3, 0, 2, 1, 3, 3, 3, 1, 0, 3, 1, 1, 0, 0, 3, 0, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 0, 2, 3, 2, 2, 1, 0, 0, 0, 0, 1, 0, 2, 1, 0, 3, 2, 1, 0, 0, 3, 2, 0, 2, 2, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0, 2, 1, 1, 1, 2, 3, 1, 1, 1, 0, 1, 2, 2, 1, 3, 1, 0, 3, 2, 3, 2, 0, 0, 3, 2, 2, 0, 2, 3, 3, 0, 2, 2, 2, 3, 0, 2, 3, 3, 2, 3, 2, 0, 0, 3, 3, 0, 0, 3, 0, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write prediction to a CSV file"
      ],
      "metadata": {
        "id": "XFxsPlHm77TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(predict):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ],
      "metadata": {
        "id": "2ln_muE_79Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hpUCYbu92GjS"
      }
    }
  ]
}